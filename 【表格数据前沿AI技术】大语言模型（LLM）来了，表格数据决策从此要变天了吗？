【表格数据前沿AI技术】大语言模型（LLM）来了，表格数据决策从此要变天了吗？
摘要
从医疗保健到气候、金融，再到ICT数据，表格数据无所不在。由于表格数据的异质属性，对表格数据进行决策一直是一个令人头疼的问题，在实际项目应用中，是采用树模型还是采用深度学习模型进行表格数据的决策也一直是一个颇具争议的热点话题。当下，大语言模型由于其强大的涌现能力被炒的热火朝天，能否借助大语言模型帮助表格数据实现更好的决策是我们今天想探讨的话题，大语言模型来了，表格数据决策能搭上便车，完成对经典树模型与深度小模型的弯道超车吗？
自由讨论详情
1、背景介绍：
        我司品宽项目xxx是ICT领域下的一个经典的表格数据二分类项目，该项目的背景由此可以找到：
https://jx.huawei.com/community/comgroup/postsDetails?postId=6227f893e7694fe6b30ca2df4f56bcb8&noTop=true&type=freePost&commentId=e03a7a8a73474f0ba02e64b02b4c47d3。
        在该项目中，经过前期与各位专家的探讨，一方面，我们试过经典的树模型：孤立森林模型、随机森林模型、GBDT模型，也试过其组合模型，在最好的情况下，在数据质量评估策略的加持下，我们的算法在top5%下，查全率达到60%，在top1%下，查全率达到45%，虽然达到了业务需求，但从算法角度讲，仍有太大的提升空间，不应该止步于此；另一方面，我们也试过一些深度学习模型: UNet、ResNet、Transformer，但实际效果还更为逊色。如何进一步提升算法模型对表格数据决策的效果呢？
 
2、痛点诉求：
（1）大量无标签数据与少量有标签数据：数据来源于现网采集，无标签且数据量过亿，有标签的数据需要人工去处理，注定标签量不大；
（2）多场景应用：模型需要泛化能力强，能够适用多个差异化的局点部署而不出现性能劣化；
（3）更高的查全率：在指定数据量下完成更高的查全率；
 
3、解决方案：
        在大模型火热的时代，我们很自然地会想到借用大模型的力量，更细致一点的说是借鉴领域大模型，然后去微调。最近调研到了一篇TabLLM似乎给了新的希望。以下是TabLLM的原理图：
 
图1  TabLLM原理
该模型总共分为4步：
step1：将原始数据处理成标准的表格数据；
step2：将表格数据序列化为文本，有三种系列化方式：1）手工模板；2）表格转文本；3）大语言模型生成；
step3：添加任务提示对话；
step4：选择大语言模型，采用有标签数据微调大语言模型，并采用大语言模型推理无标签数据。
在Bank、Blood、Calhousing、Car、Credit-g、Diabetes、Heart、Income以及Jungle共9个公开数据集下，TabLLM在少量shots的场景下都取得了比经典的树模型XGBoost与神经网络模型TabPFN更为优异的成绩。
 
图2  实验结果
尽管TabLLM在少量shots下能取得骄人的成绩，但是在大量shots的情况下，TabLLM开始变得逐渐不敌传统模型，甚至我们可以看到随着数据全部有标签出现时，传统树模型再次回归领先状态。是什么导致这一现象的发生，TabLLM创作者并没有明说，有待进一步探究。
 
4、启发或建议：
TabLLM搭上了大语言模型，给表格类项目带来了新的处理范式，它能够仅在少量有标签数据下就能够带来很好的分类效果，且能够适用多种数据集，体现了它强大的泛化能力，从理论上一定程度地能够满足项目算法需求，但同样也存在许多待解决的问题。
 
5、问题和讨论：
（1）TabLLM处理多shots的能力不足问题是个例还是说这种范式都存在不足，是什么原因导致的这种不足，可以如何克服这种不足？
（2）TabLLM范式会成为未来表格数据决策的热点赛道吗？
（3）大语言模型能够克服表格数据的异质性吗？
（4）对于数据质量非常差的表格数据（高空值率、低信息），TabLLM范式能够有效处理吗？
（5）大语言模型对表格数据进行决策推理成本如何？
 
参考：
https://arxiv.org/pdf/2210.10723v2.pdf
 
相关话题：
表格数据前沿AI技术讨论话题合集

